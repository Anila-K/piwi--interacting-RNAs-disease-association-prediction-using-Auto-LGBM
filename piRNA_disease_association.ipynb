{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anila-K/piwi--interacting-RNAs-disease-association-prediction-using-Auto-LGBM/blob/main/piRNA_disease_association.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enDrYmSVhXZ-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCHHnjvs6yNr"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade keras tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sxwpsGh7Wyn"
      },
      "outputs": [],
      "source": [
        "!pip install np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RetVDvGg7cNC"
      },
      "outputs": [],
      "source": [
        "!pip install generic_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATLY2gUJ9_3g"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "Q6KHBRQ2yXLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x15BjwY6Rzu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "from numpy import interp\n",
        "import sklearn, tensorflow\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjI2aAil6vG3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "import random\n",
        "from keras.layers import Input, Dense\n",
        "from keras import Model\n",
        "from keras.models import Sequential, model_from_config,Model\n",
        "from keras.layers import  Dropout, Activation, Flatten\n",
        "import np_utils\n",
        "import generic_utils\n",
        "from keras.constraints import MaxNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdYn6s1i80mb"
      },
      "outputs": [],
      "source": [
        "def prepare_data(seperate=False):\n",
        "    print (\"loading data\")   #loading the dataset\n",
        "    disease_sim = np.loadtxt(\"/content/drive/MyDrive/minor project/RNA_S.txt\",dtype=float,delimiter=\"\\t\")  #piRNA similarity data\n",
        "    piRNA_sim  = np.loadtxt(\"/content/drive/MyDrive/minor project/DIS_S.txt\",dtype=float,delimiter=\"\\t\")   #disease similarity data\n",
        "    interaction = np.loadtxt(\"/content/drive/MyDrive/minor project/D_R_A.txt\",dtype=int,delimiter=\"\\t\")    # piRNA - disease association\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    link_number = 0\n",
        "    train = []\n",
        "    testf= []\n",
        "    label1 = []\n",
        "    label2 = []\n",
        "    label22=[]\n",
        "    ttf=[]\n",
        "    for i in range(0, interaction.shape[0]):   # shape[0] returns m if interaction is m*n, ie, returns no. of rows of matrix\n",
        "        for j in range(0, interaction.shape[1]):  # shape[0] returns no. of columns of matrix\n",
        "\n",
        "            if interaction[i, j] == 1:                      #for associated\n",
        "                label1.append(interaction[i,j])             #label1= labels for association(1)\n",
        "                link_number = link_number + 1               #no. of associated samples\n",
        "                #link_position.append([i, j])\n",
        "                piRNA_sim_tmp = list(piRNA_sim[i])       # piRNA similarity vector for associated samples\n",
        "                disease_sim_tmp = list(disease_sim[j])    # disease similarity vector for associated\n",
        "                tmp_sim = (piRNA_sim_tmp,disease_sim_tmp)   #concatnated feature vector for an association\n",
        "                train.append(tmp_sim)                       #train contains feature vectors of all associated samples\n",
        "            elif interaction[i,j] == 0:                     #for no association\n",
        "                label2.append(interaction[i,j])             #label2= labels for no association(0)\n",
        "                piRNA_sim_tmp1 = list(piRNA_sim[i])\n",
        "                disease_sim_tmp1 = list(disease_sim[j])\n",
        "                test_sim= (piRNA_sim_tmp1,disease_sim_tmp1) #concatenated feature vector for not having association\n",
        "                testf.append(test_sim)                    #testfnl contains feature vectors of all non associated samples\n",
        "    print(len(train))\n",
        "    print('************')\n",
        "    print(len(testf))\n",
        "    #print(link_number)\n",
        "    print(\"link_number\",link_number)   # no. of associated\n",
        "\n",
        "    m = np.arange(len(label2))\n",
        "    np.random.shuffle(m)\n",
        "\n",
        "    for x in m:\n",
        "        ttf.append(testf[x])\n",
        "        label22.append(label2[x])\n",
        "    #print('************')\n",
        "    #print(ttfnl)\n",
        "    #print('************')\n",
        "    #print(label22)\n",
        "    for x in range(0, link_number):                         #for equalizing positive and negative samples\n",
        "        tfnl= ttf[x]                                    #tfnl= feature vector pair for no association\n",
        "        lab= label22[x]                                      #lab= label of the above mentioned feature vector pair(0)\n",
        "        #print(tfnl)\n",
        "        #print('***')\n",
        "        train.append(tfnl)                                  #append the non associated feature vector pairs to train till x<=no. of associated pairs\n",
        "        label1.append(lab)                                   #append the labels of non associated pairs(0) to label1\n",
        "\n",
        "    print(len(train))\n",
        "    print(len(label1))\n",
        "    print(len(testf))\n",
        "    return np.array(train), label1, np.array(testf)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_array_format(data):    #data=X  , X= all the piRNA features, disease features\n",
        "    formated_matrix1 = []\n",
        "    formated_matrix2 = []\n",
        "    for val in data:\n",
        "        formated_matrix1.append(val[0])   #contains piRNA features\n",
        "        formated_matrix2.append(val[1])   #contains disease features\n",
        "    return np.array(formated_matrix1), np.array(formated_matrix2)"
      ],
      "metadata": {
        "id": "B3IkB7IGg1nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def D_auto(x_train):\n",
        "\n",
        "    encoding_dim = 128\n",
        "    input_img = Input(shape=(523,))\n",
        "    encoded = Dense(400, activation='relu')(input_img)   # 400 - output (input layer)\n",
        "    encoded = Dense(300, activation='relu')(encoded)    # 300 - output (hidden layer1)\n",
        "    encoded = Dense(200, activation='relu')(encoded)     # 200 - output (hidden layer2)\n",
        "    encoded = Dense(100, activation='relu')(encoded)    # 100 - output (hidden layer3)\n",
        "    encoder_output = Dense(encoding_dim)(encoded)\n",
        "    #print(encoder_output)\n",
        "# decoder layers\n",
        "    decoded = Dense(175, activation='relu')(encoder_output)\n",
        "    decoded = Dense(200, activation='relu')(decoded)\n",
        "    decoded = Dense(300, activation='relu')(decoded)\n",
        "    decoded = Dense(523, activation='tanh')(decoded)\n",
        "\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "\n",
        "    encoder = Model(input_img,encoder_output)\n",
        "\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "    autoencoder.fit(x_train, x_train,epochs=20,batch_size=100,shuffle=True)\n",
        "    #batch_size=100 original\n",
        "    encoded_imgs = encoder.predict(x_train)\n",
        "\n",
        "    print(\"???????????????????\")\n",
        "    print(encoded_imgs.shape)  #(2424,128)\n",
        "\n",
        "    return encoder_output,encoded_imgs\n",
        "\n",
        "def preprocess_labels(labels, encoder=None, categorical=True):\n",
        "    if not encoder:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(labels)\n",
        "    y = encoder.transform(labels).astype(np.int32)\n",
        "    if categorical:\n",
        "        y = to_categorical(y)\n",
        "    return y, encoder\n"
      ],
      "metadata": {
        "id": "ZuVv7-_4hBPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DeepMDA():\n",
        "    X, labels,T = prepare_data(seperate = True)     #X= array of concatenated features(train data),labels=corresponding labels, T = test data\n",
        "\n",
        "    X_data1, X_data2 = transfer_array_format(X) # X-data1 = disease features (22*22) , X_data2 = piRNA features (501*501)\n",
        "\n",
        "    print(\"************\")\n",
        "    print (X_data1.shape,X_data2.shape)  # (2424,22), (2424,501)\n",
        "    print(\"******************\")\n",
        "\n",
        "\n",
        "    X_data1= np.concatenate((X_data1, X_data2 ), axis = 1) #axis=1 , rowwise concatenation\n",
        "\n",
        "    print(\"************\")\n",
        "    print (X_data1.shape)  # (2424,523)\n",
        "    print(\"******************\")\n",
        "\n",
        "    y, encoder = preprocess_labels(labels)# labels labels_new\n",
        "    print(len(y))\n",
        "    num = np.arange(len(y))   #num gets an array like num = [0,1,2...len(y)], len(y) = 501*22 = 36352\n",
        "    #print(num)\n",
        "    np.random.shuffle(num)\n",
        "    X_data1 = X_data1[num]\n",
        "    #X_data2 = X_data2[num]\n",
        "    y = y[num]\n",
        "\n",
        "    t=0\n",
        "    mean_tpr = 0.0\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "    encoder,X_data1 = D_auto(X_data1)\n",
        "\n",
        "    num_cross_val = 5\n",
        "    all_performance_LGBM = []\n",
        "    all_labels = []\n",
        "    all_prob = {}\n",
        "    all_prob[0] = []\n",
        "    all_prob[1] = []\n",
        "    all_prob[2] = []\n",
        "    all_prob[3] = []\n",
        "    all_averrage = []\n",
        "    for fold in range(num_cross_val):\n",
        "        train1 = np.array([x for i, x in enumerate(X_data1) if i % num_cross_val != fold])\n",
        "        test1 = np.array([x for i, x in enumerate(X_data1) if i % num_cross_val == fold])\n",
        "        print(len(train1))\n",
        "        print(len(test1))\n",
        "        train_label = np.array([x for i, x in enumerate(y) if i % num_cross_val != fold])\n",
        "        test_label = np.array([x for i, x in enumerate(y) if i % num_cross_val == fold])\n",
        "        #print(test_label)\n",
        "        #print(\"$$$$$$$$$$$$\",test1)\n",
        "        #print(test2)\n",
        "\n",
        "        real_labels = []\n",
        "        for val in test_label:\n",
        "            if val[0] == 1:\n",
        "                real_labels.append(0)\n",
        "            else:\n",
        "                real_labels.append(1)\n",
        "        #print(\"the size of real \",len(real_labels))\n",
        "        train_label_new = []\n",
        "        for val in train_label:\n",
        "            if val[0] == 1:\n",
        "                train_label_new.append(0)\n",
        "            else:\n",
        "                train_label_new.append(1)\n",
        "        prefilter_train = train1\n",
        "        prefilter_test = test1\n",
        "       # print(real_labels)\n",
        "\n",
        "\n",
        "        #clf = RandomForestClassifier(n_estimators=200)\n",
        "        #clf = XGBClassifier(n_estimators = 200, learning_rate = 0.2, max_depth= 15)\n",
        "        clf = LGBMClassifier(n_estimators=  150,num_leaves= 10, learning_rate = 0.2, max_depth= 15)\n",
        "        #clf = AdaBoostClassifier(n_estimators = 200, learning_rate = 0.2,random_state=0)\n",
        "        #clf = CatBoostClassifier(n_estimators = 200, learning_rate = 0.2,random_state=0)\n",
        "\n",
        "\n",
        "        clf.fit(prefilter_train, train_label_new)    #***Training\n",
        "\n",
        "        ae_y_pred_prob = clf.predict_proba(prefilter_test)[:,1]   #**testing\n",
        "\n",
        "        #print(ae_y_pred_prob)\n",
        "\n",
        "        proba = transfer_label_from_prob(ae_y_pred_prob)\n",
        "        #print(proba)\n",
        "        #print(encoder.shape)\n",
        "        #print(X_data1.shape)\n",
        "        #print(X_data2.shape)\n",
        "        acc, precision, sensitivity, specificity, MCC, f1_score = calculate_performace(len(real_labels), proba,  real_labels)\n",
        "\n",
        "        fpr, tpr, auc_thresholds = roc_curve(real_labels, ae_y_pred_prob)\n",
        "        auc_score = auc(fpr, tpr)\n",
        "#        print(\"Length\")\n",
        "#        print(len(real_labels))\n",
        "        ## AUPR score add\n",
        "        precision1, recall, pr_threshods = precision_recall_curve(real_labels, ae_y_pred_prob)\n",
        "        aupr_score = auc(recall, precision1)\n",
        "        print (\"AUTO-LGBM:\",acc, precision, sensitivity, specificity, MCC, auc_score, aupr_score,f1_score)\n",
        "        all_performance_LGBM.append([acc, precision, sensitivity, specificity, MCC, auc_score, aupr_score,f1_score])\n",
        "        t =t+1  #  AUC fold number\n",
        "\n",
        "        pyplot.plot(fpr,tpr,label= 'ROC fold %d (AUC = %0.4f)' % (t, auc_score))\n",
        "        mean_tpr += interp(mean_fpr, fpr, tpr) # one dimensional interpolation\n",
        "        mean_tpr[0] = 0.0\n",
        "\n",
        "        pyplot.xlabel('False positive rate, (1-Specificity)')\n",
        "        pyplot.ylabel('True positive rate,(Sensitivity)')\n",
        "        pyplot.title('Receiver Operating Characteristic curve: 5-Fold CV')\n",
        "        pyplot.legend()\n",
        "\n",
        "    mean_tpr /= num_cross_val\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    pyplot.plot(mean_fpr, mean_tpr,'--' ,linewidth=2.5,label='Mean ROC (AUC = %0.4f)' % mean_auc)\n",
        "    pyplot.legend()\n",
        "    pyplot.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print('*******AUTO-LGBM*****')\n",
        "    print ('mean performance of LGBM using raw feature')\n",
        "    print (np.mean(np.array(all_performance_LGBM), axis=0))\n",
        "    Mean_Result=[]\n",
        "    Mean_Result= np.mean(np.array(all_performance_LGBM), axis=0)\n",
        "    print ('---' * 20)\n",
        "    print('Mean-Accuracy=', Mean_Result[0],'\\n Mean-precision=',Mean_Result[1])\n",
        "    print('Mean-Sensitivity=', Mean_Result[2], '\\n Mean-Specificity=',Mean_Result[3])\n",
        "    print('Mean-MCC=', Mean_Result[4],'\\n' 'Mean-auc_score=',Mean_Result[5])\n",
        "    print('Mean-Aupr-score=', Mean_Result[6],'\\n' 'Mean_F1=',Mean_Result[7])\n",
        "    print ('---' * 20)\n",
        "\n",
        "    print(X_data1.shape)\n"
      ],
      "metadata": {
        "id": "jKqYUAfdhJJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_label_from_prob(proba):\n",
        "    label = [1 if val>=0.5 else 0 for val in proba]\n",
        "    return label\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    DeepMDA()\n"
      ],
      "metadata": {
        "id": "XMQ1FFu2hYj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_performace(test_num, pred_y,  labels): #pred_y = proba, labels = real_labels\n",
        "    tp =0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for index in range(test_num):\n",
        "        if labels[index] ==1:\n",
        "            if labels[index] == pred_y[index]:\n",
        "                tp = tp +1\n",
        "            else:\n",
        "                fn = fn + 1\n",
        "        else:\n",
        "            if labels[index] == pred_y[index]:\n",
        "                tn = tn +1\n",
        "            else:\n",
        "                fp = fp + 1\n",
        "\n",
        "    acc = float(tp + tn)/test_num\n",
        "\n",
        "    if tp == 0 and fp == 0:\n",
        "        precision = 0\n",
        "        MCC = 0\n",
        "        f1_score=0\n",
        "        sensitivity =  float(tp)/ (tp+fn)\n",
        "        specificity = float(tn)/(tn + fp)\n",
        "    else:\n",
        "        precision = float(tp)/(tp+ fp)\n",
        "        sensitivity = float(tp)/ (tp+fn)\n",
        "        specificity = float(tn)/(tn + fp)\n",
        "        MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
        "        f1_score= float(2*tp)/((2*tp)+fp+fn)\n",
        "\n",
        "    return acc, precision, sensitivity, specificity, MCC,f1_score\n"
      ],
      "metadata": {
        "id": "nWMFpNP6Qcgt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+g3S8oq1QOQtsM2+dztQ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}